<html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=icon href=/images/favicon-96x96.png><link rel=stylesheet type=text/css href="//fonts.googleapis.com/css?family=Open+Sans"><link rel=stylesheet href=/scss/global.min.ae6b060df7a6cc9d3fc742acd2d5dad1ccc9ba6004fb2b70d30d45768e08f41b.css><link rel=stylesheet href=/css/prism.css><link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel=stylesheet><title>Scaling et Optimation des coûts Infrastructure | Blog technique e-TF1</title><meta name=description content="Découvrez comment nous optimisons les coût infrastructure tout en tenant des pic de charges importants."><meta name=robots content="index, follow"><meta name=google-site-verification content="8mELmXNpnm-09GtDb3i1kq4Jfq_iR94-yqgo5wN9CdY"><meta property="og:title" content="Scaling et Optimation des coûts Infrastructure | Blog technique e-TF1"><meta property="og:site_name" content="Blog technique e-TF1"><meta property="og:description" content="Découvrez comment nous optimisons les coût infrastructure tout en tenant des pic de charges importants."><meta property="og:url" content="https://tech.tf1.fr/post/2024/iops/cost-optimisation/"><meta property="og:type" content="website"><meta property="og:locale" content="fr_FR"><meta property="og:image" content="https://tech.tf1.fr/post/2024/iops/cost-optimisation/images/hero.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="Scaling et Optimation des coûts Infrastructure | Blog technique e-TF1"><link rel=canonical href=https://tech.tf1.fr/post/2024/iops/cost-optimisation/><meta name=twitter:description content="Découvrez comment nous optimisons les coût infrastructure tout en tenant des pic de charges importants."><meta name=twitter:image content="https://tech.tf1.fr/post/2024/iops/cost-optimisation/images/hero.jpg"><meta property="article:published_time" content="2024-12-16T08:00:00+00:00"><meta property="article:updated_time" content="2024-12-16T08:00:00+00:00"><meta property="keywords" content="mytf1, tf1, tf1+, streaming, player, video, go, golang, react, js, javascript, css, android, ios, kotlin, swift, nginx, drm, widevine, elemental, aws, mongodb, kafka"><link rel=alternate type=application/rss+xml title="Blog technique e-TF1" href=https://tech.tf1.fr/index.xml></head><body class=line-numbers><script src=/js/initColors.js></script><div class=layout-styled><section class=section><div class=nav-container><a class=logo-link href=/><img src=/images/logo-tf1plus-white.svg alt=logo id=logo-desktop>
<span class=header-hidden>Navigate back to the homepage</span></a><div class=nav-controls><button id=copyButton class=icon-wrapper><svg class="icon-image" width="24" height="20" viewBox="0 0 24 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M2 5C2 3.34328 3.34328 2 5 2h9c1.6567.0 3 1.34328 3 3V9c0 1.6567-1.3433 3-3 3H10C9.44771 12 9 12.4477 9 13S9.44771 14 10 14h4c2.7613.0 5-2.2387 5-5V5c0-2.76128-2.2387-5-5-5H5C2.23872.0.0 2.23872.0 5V9c0 1.4938.656313 2.8361 1.6935 3.7509C2.10768 13.1163 2.73961 13.0767 3.10494 12.6625 3.47028 12.2483 3.43068 11.6164 3.0165 11.2511 2.39169 10.6999 2 9.89621 2 9V5zm5 6c0-1.65672 1.34328-3 3-3h4C14.5523 8 15 7.55228 15 7S14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11v4c0 2.7613 2.23872 5 5 5h9c2.7613.0 5-2.2387 5-5V11C24 9.50621 23.3437 8.16393 22.3065 7.24906 21.8923 6.88372 21.2604 6.92332 20.8951 7.3375 20.5297 7.75168 20.5693 8.38361 20.9835 8.74894 21.6083 9.30007 22 10.1038 22 11v4c0 1.6567-1.3433 3-3 3H10c-1.65672.0-3-1.3433-3-3V11z" fill="#000"/></svg><div id=toolTip class=tool-tip>copied</div><input id=copyText style=opacity:0 type=text class=tool-tip></button>
<button id=themeColorButton class=icon-wrapper><div id=sunRays class=sun-rays></div><div id=moonOrSun class=moon-or-sun></div><div id=moonMask class=moon-mask></div></button></div></div></section><script src=/js/toggleLogos.js></script>
<script src=/js/toggleColors.js></script>
<script src=/js/copyUrl.js></script><section class="section narrow"><section id=articleHero class="section narrow"><div class=article-hero><header class=article-header><h1 class=article-hero-heading>Scaling et Optimation des coûts Infrastructure</h1><div class=article-hero-subtitle><div class=article-meta><a href=/authors/mbugeia/ class=article-author-link><div class=article-author-avatar><img src=/authors/mbugeia/avatar.jpg></div><strong>Maxime Bugeia</strong>
<span class=hide-on-mobile>,&nbsp;</span></a>
<script src=/js/collapseAuthors.js></script>
Publié le 16 décembre 2024 • 14 minutes</div></div></header><div class=article-hero-image id=ArticleImage__Hero><img src=/post/2024/iops/cost-optimisation/images/hero.jpg></div></div></section><aside id=progressBar class=aside-container><div class=aside-align><div><div class=overlap-container></div></div></div><div class=progress-container tabindex={-1}><div class=track-line aria-hidden=true><div id=progressIndicator class=progress-line></div></div></div></aside><article id=articleContent class=post-content style=position:relative><h2 id=la-plateforme-etf1>La plateforme eTF1</h2><p>Chez TF1, la plateforme eTF1 rassemble les marques clés TF1+, TF1 Info, et TfouMax. Pour répondre aux besoins de scalabilité rapides, notamment lors de grands événements sportifs et de pics d&rsquo;audience, nous avons entrepris une démarche globale visant à rendre notre infrastructure plus dynamique, plus résiliente, et plus éco-responsable.</p><h3 id=une-infrastructure-moderne-hébergée-principalement-sur-le-cloud>Une infrastructure moderne hébergée principalement sur le cloud</h3><p>Notre plateforme repose en grande partie sur des clusters Kubernetes sur lesquels tous nos applicatifs sont déployés. A cela sont associés plusieurs services managés autour de la data, tels que RDS, Elasticache, S3, MSK et OpenSearch.</p><p>L&rsquo;infrastructure est déployée as-code via Terraform associé à <a href=https://terragrunt.gruntwork.io/>Terragrunt</a> pour la factorisation de code et <a href=https://www.runatlantis.io/>Atlantis</a> pour la CI/CD.</p><p>Toutes les ressources Kubernetes de nos cluster sont managées en GitOps via <a href=https://argo-cd.readthedocs.io>ArgoCD</a>. Nous sommes également utilisateurs d&rsquo;un certains nombre d&rsquo;opérateur kubernetes de la communauté, parmis eux : <a href=https://prometheus-operator.dev>prometheus operator</a>, <a href=https://cert-manager.io/>cert-manager</a>, <a href=https://kubernetes-sigs.github.io/external-dns>external-dns</a>, <a href=https://external-secrets.io/>external-secrets</a>, <a href=https://kyverno.io/>kyverno</a>, <a href=https://docs.stakater.com/reloader/>reloader</a>, &mldr;</p><p>L&rsquo;essentiel de cette infrastructure est hébergé sur le cloud AWS, bien que nous ayons aussi une partie on-premise, notamment avec un CDN interne pour la diffusion video.</p><h2 id=une-plateforme-de-production-élastique>Une plateforme de production élastique</h2><h3 id=un-trafic-qui-évolue-en-fonction-des-programmes-et-de-lactualité>Un trafic qui évolue en fonction des programmes, et de l&rsquo;actualité</h3><p>L&rsquo;audience de eTF1 varie au cours de la journée, avec des pics le soir et un trafic réduit la nuit. Des programmes phares tels que <code>Koh Lanta</code> ou <code>The Voice</code> génèrent d&rsquo;importants volumes d’utilisateurs, tout comme les événements sportifs majeurs.</p><p>Par exemple, la Finale de coupe du monde de foot 2022​ en chiffres​
​- ​2.4 millions d&rsquo;utilisateurs (source Mediametrie)​</p><ul><li>3.6Tbps en pic​</li><li>500 000 créations de compte​</li><li>576 000 rps (mesure CDN)​</li><li>30 000 rps (services backend)</li></ul><p>De plus selon les composants applicatifs, les patterns de trafic peuvent être réellement différents.
<img src=images/profil_traffic_foot.png#darkmode alt="Profil de traffic match de foot" title="Illustration des profils de traffic lors d'un match de foot"></p><p>Ces pics de trafic, parfois prévisibles comme lors des matchs de foot ou de l&rsquo;annonces de résultats électoraux, peuvent aussi survenir de manière inattendue.</p><p>Exemple, sur le graphe suivant du 9 juin 2024, le jour des élections européennes, un pic important s’est ajouté à celui attendu de l&rsquo;annonce des résultats : l&rsquo;annonce de la dissolution de l’Assemblée Nationale.</p><p><img src=images/pic-dissolution.png#darkmode alt="Pic de traffic dissolution" title="Illustration d'un pic de traffic le jour de la dissolution de l'assemblée nationale le 9 juin 2024"></p><p>La plateforme doit pouvoir répondre avec un niveau de service satisfaisant​ en toutes circonstances, mais nous devons faire cela en maitrisant nos coûts. C&rsquo;est pourquoi nous avons du mettre un oeuvre un certain nombre de stratégies de scaling de la plateforme.</p><h3 id=scaling-des-clusters-avec-karpenter>Scaling des clusters avec Karpenter</h3><p><img src=images/karpenter.png#darkmode alt=karpenter title="Logo karpenter"></p><p>Pour répondre à ces variations de demande au niveau des cluster EKS, nous avons déployé <a href=https://karpenter.sh/>Karpenter</a>, un outil d&rsquo;autoscaling qui permet de provisionner automatiquement des nœuds Kubernetes en fonction des besoins des pods. Celui ci remplace cluster-autoscaler.</p><h4 id=les-atouts-de-karpenter->Les atouts de Karpenter :</h4><ul><li><strong>Évaluation automatique des contraintes</strong> : Karpenter détecte les pods &ldquo;Unschedulable&rdquo;, et répartit les pods en respectant les anti-affinités et les besoins de ressources.</li><li><strong>Configuration native Kubernetes</strong> : Basée sur des CRDs, Karpenter permet d’ajuster les instances en combinant SPOT et OnDemand pour une meilleure gestion des coûts et des interruptions.</li><li><strong>Visibilité améliorée</strong> : Grâce à Karpenter, nous avons une vision claire de la répartition des nœuds et de la diversité des instances.</li><li><strong>Consolidation des noeuds</strong> : Karpenter consolide en permanence le cluster pour assurer une utilisation optimale des noeuds en fonction des requests (CPU/RAM) des pods déployés ainsi que du prix des instances EC2.</li></ul><p>L&rsquo;image suivante créé avec eks-node-viewer est un extrait de notre cluster de production. Elle illustre bien :</p><ul><li>la diversité des types d&rsquo;instance</li><li>l&rsquo;utilisation d&rsquo;instances spot</li><li>la consolidation que fait karpenter pour remplir les noeuds</li></ul><p><img src=images/eks-node-viewer.png#darkmode alt=EKS-node-viewer title="Illustration du remplissage et de la diversité des noeud par kapenter"></p><p>Voici une exemple proche de la configuration des CRD Karpenter que nous utilisons. On peut voir :</p><ul><li>Une ressource <code>EC2NodeClass</code> qui définit les caractéristiques des instances des noeuds</li><li>Une ressource <code>NodePool</code> qui utilise l&rsquo;EC2NodeClass et définit les contraintes du nodepool en termes de limites, de consolidation ainsi que de choix d&rsquo;instance type.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>karpenter.k8s.aws/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>EC2NodeClass</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>amiFamily</span>: <span style=color:#ae81ff>AL2</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># un disque root de 100Gi pour stocker images et logs</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>blockDeviceMappings</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>deviceName</span>: <span style=color:#ae81ff>/dev/xvda</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ebs</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>encrypted</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>volumeSize</span>: <span style=color:#ae81ff>100Gi</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>volumeType</span>: <span style=color:#ae81ff>gp3</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>role</span>: <span style=color:#ae81ff>Karpenter-xxxxx</span> <span style=color:#75715e># role créé automatiquement par le module terraform</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>securityGroupSelectorTerms</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>tags</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>karpenter.sh/discovery</span>: <span style=color:#ae81ff>${cluster}</span> <span style=color:#75715e># on choisit les SG via le nom du cluster</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>subnetSelectorTerms</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>tags</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>karpenter.sh/discovery</span>: <span style=color:#ae81ff>${env}</span> <span style=color:#75715e># on choisit les subnet via le nom de l&#39;environnement</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>karpenter.sh/v1beta1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>NodePool</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#75715e># stratégie de consolidation des noeuds</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>disruption</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>budgets</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>nodes</span>: <span style=color:#ae81ff>10</span><span style=color:#ae81ff>%</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>consolidationPolicy</span>: <span style=color:#ae81ff>WhenUnderutilized</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>expireAfter</span>: <span style=color:#ae81ff>720h</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># limite de taille du cluster afin de ne pas exploser les coût</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># attention, atteindre la limite empêche tout autoscaling</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>cpu</span>: <span style=color:#ae81ff>1200</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>1800Gi</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>nodeClassRef</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>karpenter.k8s.aws/v1beta1</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>kind</span>: <span style=color:#ae81ff>EC2NodeClass</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>name</span>: <span style=color:#ae81ff>default</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>requirements</span>:
</span></span><span style=display:flex><span>      <span style=color:#75715e># Des instances spot dans le nodepool par défaut !</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>karpenter.sh/capacity-type</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>        - <span style=color:#ae81ff>spot</span>
</span></span><span style=display:flex><span>        - <span style=color:#66d9ef>on</span>-<span style=color:#ae81ff>demand</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>kubernetes.io/arch</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>        - <span style=color:#ae81ff>amd64</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>karpenter.k8s.aws/instance-hypervisor</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>        - <span style=color:#ae81ff>nitro</span>
</span></span><span style=display:flex><span>      <span style=color:#75715e># Des limites de taille d&#39;instances pour éviter un blast radius trop important</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>karpenter.k8s.aws/instance-cpu</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Lt</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>        - <span style=color:#e6db74>&#34;49&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>karpenter.k8s.aws/instance-memory</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Lt</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>        - <span style=color:#e6db74>&#34;100001&#34;</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>karpenter.k8s.aws/instance-category</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>        - <span style=color:#ae81ff>c</span>
</span></span><span style=display:flex><span>        - <span style=color:#ae81ff>m</span>
</span></span><span style=display:flex><span>        - <span style=color:#ae81ff>r</span>
</span></span></code></pre></div><p>Si une chose est à retenir avec l&rsquo;utilisation de Karpenter : le <strong>sizing des requests des containers est essentiel</strong>. Le choix des noeuds et la compaction du cluster nécessite que les workloads soient dimensionnées au plus juste de leur utilisation réelle.</p><p>L&rsquo;utilisation des <code>TopologySpreadConstraints</code> des <code>AntiAffinity</code> ainsi que des <code>PodDisruptionBudget</code> est également essentielle pour garantir la <strong>Haute Disponibilité</strong> des applicatifs dans un contexte où Karpenter va continuellement consolider le cluster et donc rescheduler des pods et des noeuds.</p><p>Voici par exemple un extrait de configuration que nous mettons sur chacun de nos deployment :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>  <span style=color:#75715e># avec l&#39;antiaffinity on s&#39;assure que les pods ne soit pas tous sur le même host</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>podAntiAffinity</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>preferredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>podAffinityTerm</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>labelSelector</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>app.kubernetes.io/name</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>              - <span style=color:#ae81ff>deployment-name</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>topologyKey</span>: <span style=color:#ae81ff>kubernetes.io/hostname</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>weight</span>: <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>  <span style=color:#75715e># avec la topologySpreadConstraints on s&#39;assure que les pods ne soient pas tous sur la même AZ</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>topologySpreadConstraints</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>labelSelector</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>app.kubernetes.io/name</span>: <span style=color:#ae81ff>deployment-name</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>maxSkew</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>topologyKey</span>: <span style=color:#ae81ff>topology.kubernetes.io/zone</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>whenUnsatisfiable</span>: <span style=color:#ae81ff>ScheduleAnyway</span>
</span></span></code></pre></div><h3 id=scaling-des-applications-avec-keda>Scaling des applications avec KEDA</h3><p><img src=images/keda.png#darkmode alt=KEDA title="Logo KEDA (Kubernetes Event-driven Autoscaling)"></p><p>Pendant plusieurs années, notre plateforme utilisait le Horizontal Pod Autoscaler (HPA) pour gérer l’autoscaling en fonction de la charge CPU et de la mémoire. Avec l’arrivée de <a href=https://keda.sh>KEDA (Kubernetes Event-driven Autoscaling)</a>, nous avons franchi un cap en introduisant des métriques métier comme levier pour le scaling, permettant ainsi des ajustements plus fins et une réactivité accrue.</p><p>KEDA nous permet de configurer des &ldquo;triggers&rdquo; variés (Prometheus, SQS, Cron) pour scalabiliser nos applications en fonction des besoins métier, comme l&rsquo;augmentation du nombre d&rsquo;utilisateurs ou la consommation de ressources spécifiques. Cette approche réduit les délais de montée en charge et optimise la réponse aux variations de trafic, améliorant l’expérience utilisateur et l&rsquo;efficacité des ressources allouées.</p><p>KEDA utilise une CRD <code>ScaledObject</code> pour scaler les deployment. Voici un exemple de configuration utilisée :</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>keda.sh/v1alpha1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>ScaledObject</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app.kubernetes.io/name</span>: <span style=color:#ae81ff>middle-catalog-graphql</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>scaledobject.keda.sh/name</span>: <span style=color:#ae81ff>middle-catalog-graphql</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>middle-catalog-graphql</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>namespace</span>: <span style=color:#ae81ff>platform</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>advanced</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>horizontalPodAutoscalerConfig</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>behavior</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>scaleDown</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>policies</span>:
</span></span><span style=display:flex><span>          - <span style=color:#f92672>periodSeconds</span>: <span style=color:#ae81ff>180</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>type</span>: <span style=color:#ae81ff>Pods</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>value</span>: <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>stabilizationWindowSeconds</span>: <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>cooldownPeriod</span>: <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>fallback</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>failureThreshold</span>: <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>maxReplicaCount</span>: <span style=color:#ae81ff>300</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>minReplicaCount</span>: <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>pollingInterval</span>: <span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>scaleTargetRef</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>middle-catalog-graphql</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>triggers</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>type</span>: <span style=color:#ae81ff>Utilization</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>value</span>: <span style=color:#e6db74>&#34;70&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>cpu</span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>type</span>: <span style=color:#ae81ff>Utilization</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>value</span>: <span style=color:#e6db74>&#34;90&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>memory</span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>metricName</span>: <span style=color:#ae81ff>http_total_requests_by_second</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>query</span>: <span style=color:#ae81ff>sum(irate(http_request_duration_seconds_count{app=&#34;middle-catalog-graphql&#34;,</span>
</span></span><span style=display:flex><span>        <span style=color:#ae81ff>identifier=&#34;graphql&#34;, method!=&#34;OPTIONS&#34;}[2m]))</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>serverAddress</span>: <span style=color:#ae81ff>http://kube-prometheus-stack-prometheus.observability:9090</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>threshold</span>: <span style=color:#e6db74>&#34;45&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>prometheus</span>
</span></span></code></pre></div><p>Dans cet exemple nous utilisons 3 triggers pour scaler l&rsquo;applicatif :</p><ul><li>Le CPU</li><li>La mémoire</li><li>Une métrique prometheus sur l&rsquo;augmentation du nombre de requêtes par secondes</li></ul><p>C&rsquo;est principalement ce dernier trigger qui nous permet d&rsquo;être plus réactif sur le scaling. Pour valider le dynamisme et trouver les bon seuils, cela s&rsquo;est fait de manière expérimentale via des tests de charge.</p><p>KEDA permets d&rsquo;aller beaucoup plus loin que cet exemple, il est capable de scaler des workload Kubernetes sur une multitude de triggers (queue SQS, topic Kafka, cron, &mldr;) à utiliser selon le besoin métier.</p><h3 id=la-mise-en-œuvre>La mise en œuvre</h3><h4 id=les-pratiques-mises-en-place>Les pratiques mises en place</h4><p>Pour garantir un autoscaling dynamique et réactif, plusieurs pratiques ont été adoptées :</p><ul><li>Tests de performance : Les tests de charge ont permis de valider l’efficacité de l’autoscaling avec KEDA et Karpenter et mettre en évidence le dynamisme de l&rsquo;autoscaling.​</li><li>Overprovisioning de 5 % : Un léger surplus sur le cluster garantit la disponibilité immédiate en cas de pic imprévu. Pour cela nous utilisons le chart <a href=https://github.com/codecentric/cluster-overprovisioner>Cluster Overprovisioner</a>.</li><li>Diversification des instances AWS : En utilisant des types d&rsquo;instances variés, nous améliorons la disponibilité globale et limitons la dépendance à une seule catégorie d’instances.</li><li>Optimisation des coûts : Ces stratégies ont permis une réduction de 15 % de notre facture sur les EC2, sans compromis sur la qualité de service.</li></ul><p>Gestion des <code>NodePool</code> Karpenter</p><ul><li>Un Managed Node Group est dédié à Karpenter avec des taints spécifiques</li><li>1 nodepool Karpenter à usage généraliste</li><li>1 nodepool Karpenter &ldquo;io&rdquo; pour les workloads faisant une utilisation intensive des disques</li></ul><h4 id=accompagnement-des-développeurs>Accompagnement des développeurs</h4><p>Pour tirer pleinement parti de l’architecture, un soutien actif aux équipes de développement est essentiel :</p><ul><li>Consolidation et vigilance : La consolidation de Karpenter nécessite de bien configurer les applications avec des contraintes de topologie, des budgets de perturbation (PDB), et des jobs adaptés pour minimiser les risques. (TopologySpreadConstraints, PDB, jobs&mldr;)​</li><li>Documentation : nous avons produit des guides de déploiement clairs pour aider les développeurs à suivre les bonnes pratiques.</li><li>Conformité : l’application des policies <a href=https://kyverno.io>Kyverno</a> valide la conformité des configurations et renforce la sécurité de notre environnement.</li><li>Helm chart universel : nous fournissons un chart Helm standardisée aux développeurs qui intègre nos bonnes pratiques par défaut.</li></ul><h2 id=loptimisation-des-coûts-hors-prod>L&rsquo;optimisation des coûts hors prod</h2><p>Les environnements de développement et de test peuvent rapidement devenir des sources de dépenses importantes s’ils ne sont pas gérés efficacement. Voici quelques stratégies clés pour limiter ces coûts.</p><h3 id=éviter-le-gaspillage>Éviter le gaspillage</h3><ul><li><strong>Dimensionnement ajusté</strong> : Limiter la taille des instances et des clusters pour coller au plus près des besoins réels. Dans le cas de nos cluster EKS c&rsquo;est Karpenter qui joue ce rôle. Pour les services managés cela est manuel.</li><li><strong>Services managés optimisés</strong> : Utiliser des configurations mono-AZ pour RDS et Elasticache là où la haute disponibilité n’est pas nécessaire.</li><li><strong>Surveillance des POCs oubliés</strong> : Nettoyer régulièrement les ressources inutilisées ou les projets pilotes abandonnés.</li></ul><h4 id=gestion-des-données-sur-s3->Gestion des données sur S3 :</h4><ul><li>Désactiver le versioning des buckets non critiques pour économiser du stockage.</li><li>Penser aux lifecycle policies</li></ul><h4 id=instances-arm-graviton-sur-aws->Instances ARM Graviton sur AWS :</h4><ul><li>Les instances Graviton (repérées par un &ldquo;g&rdquo; dans leur nom) sont plus économiques et performantes : environ 10 % de coût en moins pour 10 % de performance en plus.</li><li>Elles consomment jusqu’à 60 % d’énergie en moins que les instances classiques AMD64, contribuant ainsi à réduire l’empreinte environnementale.</li><li>Pour les services managés, la seule opération à effectuer est de changer le type d&rsquo;instance !</li></ul><h3 id=mesurer-et-corriger-lefficience-des-ressources-kubernetes>Mesurer et corriger l&rsquo;efficience des ressources Kubernetes</h3><p><img src=images/kubecost.png#darkmode alt=Kubecost title="Logo Kubecost"></p><p>Chez tf1 nous utilisons <a href=https://www.kubecost.com/>Kubecost</a> dont une licence à rétention limitée (15j) ets gratuite avec EKS.</p><p><img src=images/kubecost_eff.png#darkmode alt="Kubecost efficiency" title="Illustration de l'efficience dans kubecost"></p><p>Kubecost nous permet de donner de la visibiltié aux développeurs sur les ressources effectivement consommées sur les clusters en prod et en hors-prod afin de sizer au mieux leurs containers.</p><h3 id=extinction-des-ressources-non-utilisées>Extinction des ressources non utilisées</h3><p>Pour optimiser les coûts, nous avons mis en place l&rsquo;extinction automatique des environnements hors-production pendant les périodes creuses, comme la nuit et les week-ends. Ces environnements, souvent dédiés au développement et principalement utilisés pendant les heures ouvrées, génèrent des coûts surtout dus aux instances EC2.</p><h4 id=approche-par-cluster-eks>Approche par Cluster EKS</h4><p>Nous avons décidé d&rsquo;adopter une approche où chaque cluster est autonome dans son cycle de vie. Cette stratégie repose sur un opérateur installé sur chaque cluster hors-production qui éteint les ressources non utilisées en heures non ouvrées.</p><h3 id=solutions-envisagées>Solutions envisagées</h3><p>Nous avons évalué plusieurs solutions open source pour automatiser cette optimisation :</p><h4 id=kube-green>Kube-green</h4><p>Site officiel : <a href=https://kube-green.dev/>kube-green.dev</a>
Kube-green est une solution open source qui permet de gérer l’extinction des ressources inutilisées via des Custom Resource Definitions (CRD). Il agit principalement sur les replicas de <em>Deployments</em> et les <em>CronJobs</em>, en stockant leur état précédent dans un <em>secret</em> pour une reprise sans interruption.</p><p><strong>Inconvénients</strong> :</p><ul><li>Limité aux ressources gérées par l’opérateur : ne couvre pas toutes les ressources comme les statefulsets</li><li>Peut entrer en conflit avec les outils GitOps, compliquant le processus de déploiement continu.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>kube-green.com/v1alpha1​</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>SleepInfo​</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>working-hours​</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>weekdays</span>: <span style=color:#e6db74>&#34;1-5&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>sleepAt</span>: <span style=color:#e6db74>&#34;20:00&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>wakeUpAt</span>: <span style=color:#e6db74>&#34;08:00&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>timeZone</span>: <span style=color:#e6db74>&#34;Europe/Rome&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>suspendCronJobs</span>: <span style=color:#66d9ef>true</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>excludeRef</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>apiVersion</span>: <span style=color:#e6db74>&#34;apps/v1&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Deployment​</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>my-deployment</span>
</span></span></code></pre></div><h4 id=kubecost-cluster-turndown>Kubecost Cluster Turndown</h4><p>Site officiel : <a href=https://kubecost.com>kubecost.com</a>
Kubecost propose également une solution open source qui agit directement sur le scaling des nœuds via des CRD. Bien que non compatible avec Karpenter, il peut être utilisé pour les <em>node pools</em> managés d’EKS ou de GKE.</p><p><strong>Inconvénient</strong> :</p><ul><li>Non compatible avec Karpenter, ce qui limite son utilisation à des clusters utilisant des pools de nœuds managés. Ce qui n&rsquo;est pas notre cas.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>kubecost.com/v1alpha1​</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>TurndownSchedule​</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>example-schedule​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>finalizers</span>:
</span></span><span style=display:flex><span>  - <span style=color:#e6db74>&#34;finalizer.kubecost.com&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>start</span>: <span style=color:#e6db74>2020-03-12T00:00:00Z</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>end</span>: <span style=color:#e6db74>2020-03-12T12:00:00Z</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>repeat</span>: <span style=color:#ae81ff>daily</span>
</span></span></code></pre></div><h3 id=développement-dun-outil-interne-pour-lextinction-automatisée>Développement d’un Outil Interne pour l&rsquo;Extinction Automatisée</h3><p>Les outils existants n&rsquo;étant pas satisfaisants pour répondre aux besoins spécifiques de notre infrastructure, nous avons donc développé un outil interne permettant une gestion des ressources Karpenter. Cet outil prend en charge plusieurs opérations d&rsquo;extinction et de reprise pour les <code>NodePool</code> Karpenter :</p><ul><li><strong>Sauvegarde et destruction des node pools Karpenter</strong> : Avant chaque extinction, l’outil sauvegarde l’état des <code>NodePool</code>, puis les détruit via un delete de la CRD.</li><li><strong>Désactivation temporaire des alertes</strong> : L’outil désactive les alertes dans <em>Alertmanager</em> et crée des silences temporaires avant chaque extinction, minimisant ainsi les notifications superflues pendant les périodes de fermeture.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>schedulers</span>:
</span></span><span style=display:flex><span>- <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;daily-turndown-without-weekend&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>karpenterEnabled</span>: <span style=color:#66d9ef>true</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>sleepAt</span>: <span style=color:#e6db74>&#34;0 21 * * 1-4&#34;</span> <span style=color:#75715e># All days of the week at 21:00​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>wakeUpAt</span>: <span style=color:#e6db74>&#34;50 6 * * 2-5&#34;</span> <span style=color:#75715e># All days of the week at 06:50 the next day​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>timezone</span>: <span style=color:#e6db74>&#34;Europe/Paris&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>- <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;weekly-turndown-weekend&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>karpenterEnabled</span>: <span style=color:#66d9ef>true</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>sleepAt</span>: <span style=color:#e6db74>&#34;0 21 * * 5&#34;</span> <span style=color:#75715e># All Fridays at 21:00​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>WakeUpAt</span>: <span style=color:#e6db74>&#34;50 6 * * 1&#34;</span> <span style=color:#75715e># All Mondays at 06:50​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>timezone</span>: <span style=color:#e6db74>&#34;Europe/Paris&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span><span style=color:#f92672>alertManagers</span>:
</span></span><span style=display:flex><span>- <span style=color:#f92672>url</span>: <span style=color:#e6db74>&#34;http://internal-alertmanager.observability.svc.cluster.local:9093&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>filters</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;cluster&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>value</span>: <span style=color:#ae81ff>mycluster​</span>
</span></span><span style=display:flex><span>- <span style=color:#f92672>url</span>: <span style=color:#e6db74>&#34;https://external-alertmanager.exemple.com&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>filters</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>name</span>: <span style=color:#e6db74>&#34;cluster&#34;</span><span style=color:#ae81ff>​</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>value</span>: <span style=color:#ae81ff>mycluster</span>
</span></span></code></pre></div><p>A la destruction du nodepool Karpenter, les instances EC2 s&rsquo;éteignent automatiquement. A sa re création, Karpenter rallume des noeuds pour instancier tous les pods.</p><h4 id=inconvénients>Inconvénients</h4><p>Notre outil interne présente toutefois certains défis :</p><ul><li><strong>Drift temporaire avec Terraform</strong> : Étant donné que les <em>node pools</em> Karpenter sont créés et gérés via Terraform, il se crée un <em>drift</em> (décalage) temporaire entre l’état réel des ressources et celui prévu dans notre configuration Terraform.</li><li><strong>Non open-source</strong> : Le choix de développer un outil interne implique un investissement en maintenance et une dépendance vis-à-vis de nos propres équipes. Nous envisageons d’étudier l’intégration de ces fonctionnalités dans un outil open-source pour réduire cette charge de maintenance et bénéficier de mises à jour de la communauté.</li></ul><h3 id=aller-plus-loin--extinction-des-ressources-au-delà-de-kubernetes>Aller plus loin : Extinction des ressources au-delà de Kubernetes</h3><p>Pour optimiser encore davantage les coûts, nous explorons l’extinction de ressources situées en dehors de Kubernetes. Ces ressources, souvent associées à des données ou à des services périphériques, nécessitent une orchestration spécifique. Toutefois, cette stratégie s’applique uniquement aux services payants en cas d’inutilisation, afin d’éviter toute manipulation superflue des ressources gratuites.</p><p>Exemple : extinction des clusters RDS ou opensearch</p><h4 id=gestion-des-ressources-cloud-créées-via-kubernetes>Gestion des ressources cloud créées via Kubernetes</h4><p>Certaines ressources cloud, telles que les load balancers créés automatiquement (par les ingress ou services de type <em>LoadBalancer</em>) et les éléments provisionnés via des solutions comme Crossplane, peuvent représenter des coûts non négligeables. La gestion de leur cycle de vie est complexe, car ces ressources dépendent directement de Kubernetes et requièrent des stratégies d’extinction spécifiques, l&rsquo;extinction des noeuds ne suffit pas.</p><p>Une approche possible serait d&rsquo;étendre notre outil d"extinction de nodepool pour supporter la destruction de plus de types de ressources, et laisser les outils de gitops faire pour la reconstruction au réveil des noeuds.</p><h4 id=approche-par-terraform-destroy>Approche par <em>Terraform Destroy</em></h4><p>Une autre approche possible consisterait à détruire tout ou partie de l&rsquo;infrastructure via des <em>terraform destroy</em> et de reconstruire via des <em>terraform apply</em>. Cette méthode pourrait permettre d’atteindre un niveau d’extinction plus avancé, en contrepartie d&rsquo;un temps de reconstruction souvent plus important. Par exemple on sait qu&rsquo;un cluster EKS mets aujourd&rsquo;hui plus de 20min à être construit, idem pour une instance RDS, là où un cluster OpenSearch peut mettre jusqu&rsquo;à 45min pour s&rsquo;initialiser. Il convient aussi souvent de ne pas détruire certains composant clé (comme le réseau) pour éviter une complexité trop importante dans le cycle de reconstruction.</p><h2 id=conclusion>Conclusion</h2><p>La plateforme eTF1 a su évoluer pour répondre à des besoins critiques de scalabilité, en particulier lors des pics de trafic générés par des événements majeurs. En intégrant des outils comme Karpenter pour le scaling des clusters Kubernetes et KEDA pour des métriques métier précises, nous avons considérablement amélioré notre capacité à absorber des variations de charge tout en maîtrisant nos coûts.</p><p>Au-delà des clusters de production, l’optimisation des environnements hors production est devenue un levier clé. Grâce à des pratiques comme l’extinction automatique des ressources non utilisées et la diversification des types d’instances, nous avons réduit significativement les dépenses inutiles.</p><p>Cette démarche s’inscrit dans une logique pragmatique : fournir une plateforme performante et résiliente tout en limitant son empreinte financière et écologique. Ce travail n’est pas une fin en soi : il ouvre la voie à d’autres initiatives pour améliorer l’efficience globale de nos infrastructures.</p></article><section id=articleNext class="section nartrow"><h3 class=footer-next-heading>Plus d'articles</h3><div class=footer-spacer></div><div class=next-articles-grid numberofarticles={numberOfArticles}><div class=post-row><a href=/post/2024/qa/migration-argo/ class=article-link id=article-link-bigger><div><div class=image-container><img src=/post/2024/qa/migration-argo/images/argo-logo.svg class=article-image></div><div><h2 class=article-title>Migration de Jenkins vers Argo</h2><p class=article-excerpt>Comment nous avons changé d'orchestrateur de tests automatisés</p><div class=article-metadata>2 septembre 2024 • 7 minutes</div></div></div></a><a href=/post/2024/ia/inference-llm-tgi/ class=article-link><div><div class=image-container><img src=/post/2024/ia/inference-llm-tgi/images/hero.jpg class=article-image></div><div><h2 class=article-title>Déploiement d'un LLM à l'échelle avec TGI</h2><p class=article-excerpt>Découvrez comment nous réalisons l'inférence de nos LLMs en production.</p><div class=article-metadata>26 juin 2024 • 9 minutes</div></div></div></a></div></div></section></section><script src=/js/progressBar.js></script><div class=footer-gradient></div><div class="section narrow"><div class=footer-hr></div><div class=footer-container><div class=footer-text><img src=/images/logo_tf1lg.png class=footer-logo>TF1 Copyright © 2025 e-TF1</div><div class=social-icon-outer><div class=social-icon-container><a href=https://www.welcometothejungle.com/fr/companies/groupe-tf1><svg class="social-icon-image" viewBox="7 7 26 26" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" alt="Rejoingez nous !" title="Rejoignez nous !"><path d="M31.347322 11.295661C30.1466441 9.31125424 26.6585085 8.44345763 24.1202034 11.0048136 23.9785085 11.1532881 23.7913898 11.6054915 24.3554576 12.2149831c1.181017 1.258305 7.340339 7.7179661 5.0616949 13.36-1.1071186 2.7430508-4.2555932 2.2705084-5.438644-2.2738984C23.4991864 21.4590508 22.7595254 17.6326102 23.468678 13.0393898 23.468678 13.0393898 23.5818983 12.6082034 23.3995254 12.4705763 23.2734237 12.3743051 23.0707119 12.4143051 22.8103729 12.8312542 22.7452881 12.936339 22.7588475 12.9146441 22.6964746 13.0265085L22.6924068 13.0285424c-1.7457627 2.9444068-3.5220339 6.4352542-4.3579661 7.7444068C18.7425763 18.7980339 18.2252881 16.0814237 17.4185085 13.8075254L17.2666441 13.396678C16.5215593 11.4515932 15.6259661 10.1390508 15.3541017 9.84142373 15.3215593 9.80549153 15.2408814 9.73837288 14.9744407 9.73837288H7.42461017c-.528135590000001.0-.4820339.45220342-.31525424.615593219999999 2.00474576 2.3857627 7.84610167 11.3294915 5.13762717 20.1064407C12.0381695 31.1390508 12.3663051 31.4949831 12.9066441 30.7946441c2.3742373-3.0772882 5.32-8.3227119 7.4542373-12.2542373C19.8903729 19.9037966 19.4761356 21.4217627 19.2544407 23.0122712c-.4677966 3.3572881.5247457 5.8827119 1.2508474 7.2081356C20.8768136 30.8990508 21.3696949 31.3139661 22.6456271 31.1241356c6.5071187-.9694915 8.6772882-6.7016949 9.4786441-9.6088136C33.5852881 16.215661 32.5154576 13.2258305 31.347322 11.295661" id="monogram" fill="#000"/></svg></a><span class=hidden>https://www.welcometothejungle.com/fr/companies/groupe-tf1</span>
<a href=https://www.linkedin.com/company/e-tf1/><svg class="social-icon-image" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M3.59615 13.125H.871552V4.36523H3.59615V13.125zM2.24847 3.16406c-.42969.0-.80078-.15625-1.11328-.46875-.312498-.3125-.468747-.6836-.468747-1.11328.0-.42969.156249-.800782.468747-1.113281C1.44769.156249 1.81878.0 2.24847.0s.80078.156249 1.11328.468749c.3125.312499.46875.683591.46875 1.113281.0.42968-.15625.80078-.46875 1.11328s-.68359.46875-1.11328.46875zM13.7915 13.125H11.0669V8.84765C11.0669 8.14452 11.0083 7.63671 10.8911 7.32421c-.2148-.52734-.6348-.79101-1.25976-.79101-.625.0-1.06445.23437-1.31836.70312C8.11767 7.58788 8.02001 8.10546 8.02001 8.78905V13.125H5.32471V4.36523H7.93212V5.5664H7.96142C8.15673 5.17578 8.46923 4.85351 8.89892 4.59961c.46875-.3125 1.01562-.46875 1.64058-.46875 1.2696.0 2.1582.40039 2.666 1.20117C13.5962 5.97656 13.7915 6.97265 13.7915 8.3203V13.125z" fill="#73737d"/></svg></a><span class=hidden>https://www.linkedin.com/company/e-tf1/</span>
<a href=https://github.com/etf1><svg class="social-icon-image" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M7 0C3.1325.0.0 3.21173.0 7.17706.0 10.3529 2.00375 13.0353 4.78625 13.9863 5.13625 14.0491 5.2675 13.8338 5.2675 13.6454 5.2675 13.4749 5.25875 12.9097 5.25875 12.3087 3.5 12.6406 3.045 11.8691 2.905 11.4653 2.82625 11.259 2.485 10.622 2.1875 10.4516 1.9425 10.317 1.5925 9.98508 2.17875 9.97611 2.73 9.96714 3.12375 10.4964 3.255 10.7118c.63 1.0855 1.63625.7805 2.03875.5921C5.355 10.8374 5.53875 10.5234 5.74 10.3439 4.1825 10.1645 2.555 9.54549 2.555 6.80026c0-.7805.27125-1.42644.7175-1.92883C3.2025 4.692 2.9575 3.95635 3.3425 2.96951c0 0 .58625-.1884 1.925.73565.56-.16149 1.155-.24223 1.75-.24223s1.19.08074 1.75.24223c1.3388-.93302 1.925-.73565 1.925-.73565C11.0775 3.95635 10.8325 4.692 10.7625 4.87143 11.2087 5.37382 11.48 6.01079 11.48 6.80026c0 2.7542-1.63625 3.36424-3.19375 3.54364C8.54 10.5682 8.75875 10.9988 8.75875 11.6717 8.75875 12.6316 8.75 13.4032 8.75 13.6454 8.75 13.8338 8.88125 14.0581 9.23125 13.9863 11.9963 13.0353 14 10.3439 14 7.17706 14 3.21173 10.8675.0 7 0z" fill="#73737d"/></svg></a><span class=hidden>https://github.com/etf1</span>
<a href=https://tech.tf1.fr/index.xml><svg class="social-icon-image" style="width:1em;height:1em;vertical-align:middle;fill:currentColor;overflow:hidden" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M329.142857 768q0 45.714286-32 77.714286t-77.714286 32-77.714285-32-32-77.714286 32-77.714286 77.714285-32 77.714286 32 32 77.714286zm292.571429 70.285714q1.142857 16-9.714286 27.428572-10.285714 12-26.857143 12H508q-14.285714.0-24.571429-9.428572T472 844.571429q-12.571429-130.857143-105.428571-223.714286T142.857143 515.428571Q128.571429 514.285714 119.142857 504T109.714286 479.428571V402.285714q0-16.571429 12-26.857143 9.714286-9.714286 24.571428-9.714285h2.857143q91.428571 7.428571 174.857143 46T472 515.428571q65.142857 64.571429 103.714286 148t46 174.857143zm292.571428 1.142857Q915.428571 854.857142 904 866.285714q-10.285714 11.428571-26.285714 11.428572H796q-14.857143.0-25.428571-10t-11.142858-24.285715Q752.571428 720.571428 701.714286 610T569.428571 418t-192-132.285714T144 227.428571q-14.285714-.571429-24.285714-11.142857t-10-24.857143V109.714286q0-16 11.428571-26.285715 10.285714-10.285714 25.142857-10.285714H148q149.714286 7.428571 286.571429 68.571429t243.142857 168q106.857143 106.285714 168 243.142857t68.571428 286.571428z"/></svg></a><span class=hidden>https://tech.tf1.fr/index.xml</span></div></div></div></div></div><script src=/js/prism.js></script></body></html>