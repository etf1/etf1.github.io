<html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><link rel=icon href=/images/favicon-96x96.png><link rel=stylesheet type=text/css href="//fonts.googleapis.com/css?family=Open+Sans"><link rel=stylesheet href=/scss/global.min.ae6b060df7a6cc9d3fc742acd2d5dad1ccc9ba6004fb2b70d30d45768e08f41b.css><link rel=stylesheet href=/css/prism.css><link href="https://fonts.googleapis.com/css?family=Merriweather&display=swap" rel=stylesheet><title>L'équipe Backend | Blog technique e-TF1</title><meta name=description content="Découvrez l'équipe backend qui se cache derrière MYTF1"><meta name=robots content="index, follow"><meta name=google-site-verification content="8mELmXNpnm-09GtDb3i1kq4Jfq_iR94-yqgo5wN9CdY"><meta property="og:title" content="L'équipe Backend | Blog technique e-TF1"><meta property="og:site_name" content="Blog technique e-TF1"><meta property="og:description" content="Découvrez l'équipe backend qui se cache derrière MYTF1"><meta property="og:url" content="https://tech.tf1.fr/post/2020/team/backend/"><meta property="og:type" content="website"><meta property="og:locale" content="fr_FR"><meta property="og:image" content="https://tech.tf1.fr/post/2020/team/backend/images/hero.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="L'équipe Backend | Blog technique e-TF1"><link rel=canonical href=https://tech.tf1.fr/post/2020/team/backend/><meta name=twitter:description content="Découvrez l'équipe backend qui se cache derrière MYTF1"><meta name=twitter:image content="https://tech.tf1.fr/post/2020/team/backend/images/hero.jpg"><meta property="article:published_time" content="2020-12-17T09:00:00+00:00"><meta property="article:updated_time" content="2020-12-17T09:00:00+00:00"><meta property="keywords" content="mytf1, tf1, tf1+, streaming, player, video, go, golang, react, js, javascript, css, android, ios, kotlin, swift, nginx, drm, widevine, elemental, aws, mongodb, kafka"><link rel=alternate type=application/rss+xml title="Blog technique e-TF1" href=https://tech.tf1.fr/index.xml></head><body class=line-numbers><script src=/js/initColors.js></script><div class=layout-styled><section class=section><div class=nav-container><a class=logo-link href=/><img src=/images/logo-tf1plus-white.svg alt=logo id=logo-desktop>
<span class=header-hidden>Navigate back to the homepage</span></a><div class=nav-controls><button id=copyButton class=icon-wrapper><svg class="icon-image" width="24" height="20" viewBox="0 0 24 20" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M2 5C2 3.34328 3.34328 2 5 2h9c1.6567.0 3 1.34328 3 3V9c0 1.6567-1.3433 3-3 3H10C9.44771 12 9 12.4477 9 13S9.44771 14 10 14h4c2.7613.0 5-2.2387 5-5V5c0-2.76128-2.2387-5-5-5H5C2.23872.0.0 2.23872.0 5V9c0 1.4938.656313 2.8361 1.6935 3.7509C2.10768 13.1163 2.73961 13.0767 3.10494 12.6625 3.47028 12.2483 3.43068 11.6164 3.0165 11.2511 2.39169 10.6999 2 9.89621 2 9V5zm5 6c0-1.65672 1.34328-3 3-3h4C14.5523 8 15 7.55228 15 7S14.5523 6 14 6H10C7.23872 6 5 8.23872 5 11v4c0 2.7613 2.23872 5 5 5h9c2.7613.0 5-2.2387 5-5V11C24 9.50621 23.3437 8.16393 22.3065 7.24906 21.8923 6.88372 21.2604 6.92332 20.8951 7.3375 20.5297 7.75168 20.5693 8.38361 20.9835 8.74894 21.6083 9.30007 22 10.1038 22 11v4c0 1.6567-1.3433 3-3 3H10c-1.65672.0-3-1.3433-3-3V11z" fill="#000"/></svg><div id=toolTip class=tool-tip>copied</div><input id=copyText style=opacity:0 type=text class=tool-tip></button>
<button id=themeColorButton class=icon-wrapper><div id=sunRays class=sun-rays></div><div id=moonOrSun class=moon-or-sun></div><div id=moonMask class=moon-mask></div></button></div></div></section><script src=/js/toggleLogos.js></script>
<script src=/js/toggleColors.js></script>
<script src=/js/copyUrl.js></script><section class="section narrow"><section id=articleHero class="section narrow"><div class=article-hero><header class=article-header><h1 class=article-hero-heading>L'équipe Backend</h1><div class=article-hero-subtitle><div class=article-meta><a href=/authors/ldechoux/ class=article-author-link><div class=article-author-avatar><img src=/authors/ldechoux/avatar.jpg></div><strong>Laurent Dechoux</strong>
<span class=hide-on-mobile>,&nbsp;</span></a>
<script src=/js/collapseAuthors.js></script>
Publié le 17 décembre 2020 • 14 minutes</div></div></header><div class=article-hero-image id=ArticleImage__Hero><img src=/post/2020/team/backend/images/hero.jpg></div></div></section><aside id=progressBar class=aside-container><div class=aside-align><div><div class=overlap-container></div></div></div><div class=progress-container tabindex={-1}><div class=track-line aria-hidden=true><div id=progressIndicator class=progress-line></div></div></div></aside><article id=articleContent class=post-content style=position:relative><h2 id=avant-propos>Avant propos</h2><p>Cet article a pour objectif de présenter l&rsquo;équipe Backend et n&rsquo;est en aucun cas une présentation technique détaillée des entrailles de MYTF1. Les aspects techniques seront abordés en détail dans des articles dédiés. Ici, nous nous concentrerons sur la composition de l&rsquo;équipe, son histoire et partagerons avec vous quelques unes des décisions que nous avons prises ces dernières années. Bonne lecture.</p><h2 id=qui-sommes-nous->Qui sommes nous ?</h2><p>Intégrée au sein de e-TF1 (antenne digitale du groupe TF1) l’équipe Backend a pour objectif de répondre aux problématiques suivantes :</p><ul><li>Gérer la mise en ligne et l’animation éditoriale de notre contenu</li><li>Stocker et restituer les données utilisateurs (historique et progression de lecture, programme favoris, bookmarks etc.)</li><li>Exporter/partager notre catalogue de contenu avec nos partenaires (FAI, Salto, etc.)</li><li>Fournir des API aux fronts pouvant supporter de fortes charges</li></ul><p>Elle est composée d’une dizaine de personnes ayant des profils (développeur, product owner, lead tech, internes ou externes) et des niveaux d’expérience (débutant, expérimenté, stagiaire, alternant) différents. Depuis 2018 nous avons fait le choix d’investir fortement dans le langage Go qui représente aujourd’hui la quasi intégralité de notre base de code.</p><h2 id=architecture-et-technologies>Architecture et technologies</h2><p>Nous avons fait le choix d’une architecture micro-services. Les différentes composantes métier sont réparties en services dédiés, qui communiquent principalement via GRPC.
Voici une liste non exhaustives de nos briques métier :</p><ul><li>CMS API : dédiée à l’animation éditoriale de notre contenu</li><li>Catalog API : dédiée à la gestion de notre catalogue de contenu</li><li>User API : dédiée à la gestion des données utilisateur</li><li>Reco API : dédiée à la recommandation de contenu</li><li>SEO API : dédiée aux problématiques SEO</li><li>Auth API : dédiée à l’identification de nos utilisateurs</li></ul><p>Pour les applications MYTF1, nous avons fait le choix d’exposer à travers une API GraphQL une vision consolidée de ces services.
En effet, l’API GraphQL agit comme une API Gateway et se charge d’exposer un modèle de données cohérent et unifié qui répond aux besoins exprimés par les équipes produit/métier.
Elle a été conçue et créée avec une vision multi-écran et doit être capable de fonctionner aussi bien pour nos applications Web, que pour les applications mobiles ou encore les box opérateurs.</p><p>Pour répondre aux différents challenges auxquels nous faisons face, nous avons choisi les technologies suivantes :</p><ul><li>Langage : <a href=https://golang.org/>Go</a></li><li>Base de données : <a href=https://www.mongodb.com/>MongoDB</a>, <a href=https://www.elastic.co/>Elasticsearch</a>, <a href=https://aws.amazon.com/dynamodb/>DynamoDB</a>, <a href=https://redis.io/>Redis</a></li><li>Event/Message broker : <a href=https://www.rabbitmq.com/>RabbitMQ</a>, <a href=https://kafka.apache.org/>Kafka</a></li><li>Frameworks Fronts : <a href=https://vuejs.org/>Vue.js</a>, <a href=https://reactjs.org/>React</a></li><li>Formats des API : <a href=https://grpc.io/>GRPC</a>, <a href=https://graphql.org/>GraphQL</a>, <a href=https://fr.wikipedia.org/wiki/Representational_state_transfer>Rest</a></li><li>Infrastructure : <a href=https://aws.amazon.com/>AWS</a>, <a href=https://kubernetes.io>Kubernetes</a>, <a href=https://www.docker.com/>Docker</a>, <a href=https://linkerd.io/>Linkerd</a></li><li>Monitoring : <a href=https://prometheus.io/>Prometheus</a>, <a href=https://grafana.com/>Grafana</a></li><li>CI/CD : <a href=https://www.jenkins.io/>Jenkins</a></li></ul><p>Cette liste, bien que fournie, peut-être amenée à évoluer en fonction des futurs besoins qui se présenteront.
En effet, une des forces de l’équipe est de savoir se remettre en question et faire table rase du passé. C’est ce que nous allons voir dans le paragraphe suivant.</p><h2 id=un-peu-dhistoire>Un peu d’histoire</h2><h3 id=2018--nouvelle-expérience-iptv>2018 : Nouvelle expérience IPTV</h3><p>Début 2018 MYTF1 se lance dans un projet radical de transformation de l’expérience utilisateur sur les box opérateurs (IPTV).
Un cahier des charges est défini et de nouveaux enjeux apparaissent :</p><ul><li>Permettre une navigation fluide du contenu</li><li>Possibilités d’éditorialisation avancées</li><li>Recommandation de contenu personnalisée</li><li>Gestion de l’historique et de la reprise de lecture</li><li>Mise en favoris des programmes</li></ul><p>À ce stade, nous sentons bien que le socle technologique existant a atteint ses limites et qu’il faut envisager des changements drastiques.
Une petite équipe est montée pour relever ce défi. Elle deviendra plus tard l&rsquo;équipe Backend.</p><p>Nous ferons alors plusieurs choix structurants :</p><ul><li>Mise en place d’une API GraphQL pour exposer les données au front</li><li>Utilisation de cache in-memory (non partagé) au niveau de l&rsquo;API GraphQL</li><li>Découpe des différents besoins en micro-services GRPC dédiés</li><li>Dénormalisation des données catalogue et éditoriales dans Elasticsearch</li><li>Gestion de la session utilisateur dans Redis</li><li>Ecriture asynchrone des données utilisateur</li><li>Utilisation d’un token JWT pour identifier l’utilisateur</li></ul><p>Dès le début, même si le projet est centré sur l’IPTV, nous avons la volonté de créer un nouveau socle technique qui sera capable d’adresser tous les écrans (Web et applications mobiles compris).
En effet, à date, il n’y a pas réellement de socle commun et chaque écran est traité séparément (avec ses propres solutions, technologies et choix techniques).
Nous avons toujours gardé cette idée dans un coin de nos têtes et elle a piloté beaucoup de nos décisions.</p><p>S’en suit alors une phase intensive de conception et développement, en effet les délais sont serrés (mise en production attendue pour Juin 2018) et nous avons beaucoup de travail à abattre (autant côté back que côté front).
L&rsquo;application sera finalement lancée en Juillet 2018, pour les utilisateurs de freebox.</p><p>La première mouture de notre nouvelle architecture backend est enfin prête :</p><p><img src=images/archi_2018.svg#darkmode alt="2018 - Première version de la nouvelle architecture backend" title="2018 - Première version de la nouvelle architecture backend"></p><p>Concrétement, nous avons deux sources de données principales, le CMS et les fichiers de recommandation (au format <a href=https://parquet.apache.org/>Parquet</a>). Via des <em>indexers</em>, nous dénormalisons régulièrement ces données dans des bases Elasticsearch qui sont ensuite exposées via des API GRPC dédiées (Catalog et Reco sur le schéma). Pour les données utilisateur, elles sont également stockées dans des bases Elasticsearch. Lorsqu&rsquo;un utilisateur se connecte, les données qui lui sont associées sont copiées dans des instances Redis qui agissent comme un cache de session. Toutes les écritures sont maintenues à jour de manière synchrone dans Redis puis propagées de manière asynchrone vers nos bases Elasticsearch via des notifications RabbitMQ.
Les données utilisateur sont accessibles via des API GRPC dédiées (History et Favorites sur le schéma). Au dessus de ces services nous avons notre API GraphQL qui se charge d&rsquo;unifier les données des différentes briques et en exposer une vision consolidée aux fronts (les box opérateurs dans le cas présent). Pour l&rsquo;identification des utilisateurs, nous avons fait le choix du token JWT. Un service dédié se charge de générer un token (sur demande du front) qui est ensuite propagé dans tous les appels GraphQL puis vers les services concernés (History et Favorites par exemple). Ainsi nous pouvons facilement identifier l&rsquo;utilisateur à l&rsquo;origine de la requête et retrouver, par exemple, son historique de lecture.</p><p>Niveau infrastucture, toutes nos applications sont packagées sous forme d&rsquo;image Docker qui sont ensuite déployées sur notre cluster Kubernetes maison (géré par notre équipe OPS). À ce stade, nous avions également fait le choix de ne pas utiliser de cache HTTP entre les box et le GraphQL. En effet les réponses mélangent à la fois données publiques (ex : catalogue) et privées (ex : historique de lecture) et se prêtent donc mal à l&rsquo;exercice. Seule solution, faire en sorte de tenir la charge en dimenssionnant correctement notre infrastructure (phase de bench) et en optimisant les applications (en utilisant, par exemple, des caches in-memory côté GraphQL pour les données publiques).</p><p>Un deuxième jalon important marquera l&rsquo;année 2018, avec la mise à disposition de notre nouvelle application IPTV sur les box Android de Bouygues Telecom. Mais pour nous, ce n&rsquo;est que le début&mldr;</p><h3 id=2019--de-liptv-à-lott>2019 : De l&rsquo;IPTV à l&rsquo;OTT</h3><p>Mi-2018, émerge chez e-TF1 l&rsquo;envie de refondre les applications MYTF1 web et mobile (dites <a href=https://fr.wikipedia.org/wiki/Service_par_contournement>OTT</a>). Au delà de l&rsquo;aspect esthétique il y a une véritable volonté de repenser le produit et le recentrer autour d&rsquo;axes stratégiques précis. Le second semestre 2018 est mis à profit pour définir précisément les contours de ce nouveau produit. Au terme de cette réflexion plusieurs priorités sont définies :</p><ul><li>Un nouveau design pour les applications web et mobile</li><li>Une expérience de lecture vidéo irréprochable</li><li>Mettre la personnalisation au centre de l&rsquo;expérience MYTF1</li><li>Améliorer les outils d&rsquo;éditorialisation</li><li>Proposer une nouvelle offre de contenus (AVOD)</li><li>Gestion de la reprise de lecture cross-device</li></ul><p>Le choix de notre nouvelle architecture backend comme socle de cette nouvelle vision du produit se fait naturellement. C&rsquo;est un nouveau challenge pour nous et là encore beaucoup de travail nous attend.</p><p>En parallèle, le second semestre 2018 nous permet de renforcer l&rsquo;équipe avec de nouveaux membres. Nous en profitons pour retravailler et améliorer certains aspects techniques de notre architecture pour préparer le futur. C&rsquo;est également l&rsquo;occasion de réfléchir aux différents choix techniques que nous allons devoir faire pour généraliser le backend à l&rsquo;ensemble des écrans MYTF1. Les principaux choix effectués sont les suivants :</p><ul><li>Migration vers AWS</li><li>Rendre l&rsquo;API GraphQL publique (exposée sur internet, jusqu&rsquo;alors elle est exposée sur des IP privées pour les différents opérateurs IPTV)</li><li>Gestion du cache HTTP et mise en place des <em>Persisted Queries</em> GraphQL</li><li>Permettre la recommandation de contenu pour les utilisateurs non connectés (introduction des personas)</li><li>Refonte du CMS</li><li>Refonte médiathèque et proxy image</li><li>Gestion du moteur de recherche</li></ul><p>Le gros des travaux commence réellement fin 2018 et concerne l&rsquo;ensemble des équipes (web, mobile, publicité, player, OPS). Là encore le planning est ambitieux, la mise en production du nouveau MYTF1 est prévue pour Avril/Mai 2019. Finalement, le lancement aura lieu le 11 Juin 2019.</p><p>Notre architecture cuvée 2019 ressemble alors à ça :</p><p><img src=images/archi_2019.svg#darkmode alt="2019 -  Schéma d&amp;rsquo;architecture backend" title="2019 - Schéma d'architecture backend"></p><p>Comme vous pouvez le voir, nous avons enrichi le socle de plusieurs nouveaux composants. Une grosse partie de nos efforts s&rsquo;est concentrée autour de nos outils internes. En particulier le CMS que nous avons entièrement refondu pour répondre aux nouveaux besoins des équipes éditoriales. Nous avons fait le choix de créer un CMS headless (ie : l&rsquo;aspect templating est totalement géré par le front) autour de MongoDB et Elasticsearch (pour le stockage des données) et de Vue.js (pour la partie interface graphique). Pour la gestion des images nous avons également créé une nouvelle médiathèque profitant des possibilités de stockages offertes par S3. De plus nous avons introduit un nouveau composant <em>Image proxy</em> dont le but est de permettre la mise à l&rsquo;échelle automatique des images (il est possible d&rsquo;obtenir une version d&rsquo;une image à une résolution différente de celle d&rsquo;origine) et leur conversion dans plusieurs formats (webp, jpeg, png, etc.). Nous avons également ajouté une mécanique de <em>crop intelligent</em> qui préserve les parties importantes d&rsquo;une image (détection des visages, entropie, etc.). Pour ce faire nous nous appuyons sur <a href=https://github.com/opencv/opencv>OpenCV</a>.</p><p><img src=images/smart_crop.jpg alt="Démonstration crop intelligent" title="Démonstration crop intelligent"></p><p>Nous avons également ajouté un composant dédié au moteur de recherche accessible dans les fronts. Il s&rsquo;appuie sur les capacités de recherche <em>full-text</em> offertes par Elasticsearch. Une autre nouveauté introduite avec la refonte MYTF1 est la notion de persona. L&rsquo;idée est de pouvoir personnaliser/adapter le contenu proposé à chaque utilisateur (même lors de sa première connexion au site ou au premier lancement de l&rsquo;application mobile). Via une API fournie par l&rsquo;équipe data, nous affectons aux utilisateurs une persona (en fonction de différents critères : utilisateur authentifié ou non, appareil utilisé, heure de connexion, dernier contenu consulté, etc.) qui va impacter la manière dont le contenu est présenté. Pour ce faire, nous calculons régulièrement des tops (vidéos les plus vues, programmes les plus consultés) pour chaque persona. Ces tops sont ensuite utilisés pour, par exemple, modifier (en fonction de la persona attribuée à l&rsquo;utilisateur) l&rsquo;ordre d&rsquo;affichage des programmes sur la home MYTF1.</p><p>Enfin une des grosses nouveautés introduite en 2019 est l&rsquo;utilisation des <em>persisted queries</em> au niveau de notre API GraphQL. Le principe est relativement simple. Au lieu d&rsquo;envoyer une requête classique (POST + body), les fronts appellent le GraphQL via des identifiants de requête (GET + query parameters). L&rsquo;intérêt est double. Premièrement on profite facilement des possibilités de cache offertes par Cloudfront et deuxièmement il nous est possible de verrouiller le GraphQL en production (ne sont autorisées que les requêtes préalablement définies dans notre référentiel). Si ce sujet vous intéresse, il est abordé en détail dans cet article : <a href=/post/2020/architecture/graphql-and-persisted-queries/>GraphQL et persisted queries</a>.</p><p>Le dernier challenge relevé dans le cadre de la refonte MYTF1 a été la migration vers AWS de l&rsquo;ensemble de notre socle backend. Nous hébergions auparavant l&rsquo;ensemble des services au sein d&rsquo;un datacenter géré par notre équipe infrastucture. Suite à un travail conjoint avec cette dernière, l&rsquo;ensemble de nos services a maintenant basculé dans le cloud nous offrant ainsi beaucoup d&rsquo;avantages (services managés, mise à l&rsquo;échelle automatique, etc.).</p><p>Le premier semestre 2019 fût donc riche pour l&rsquo;ensemble des équipes. Nous avons principalement consacré le second semestre à enrichir le produit (fourniture de nouvelles fonctionnalités) et poursuivi le déploiement IPTV à d&rsquo;autres opérateurs (SFR et VIDEOFUTUR). Nous avons également, avec le support de l&rsquo;équipe OPS, généralisé la mise en oeuvre de <a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/>HPA</a> sur l&rsquo;ensemble de nos briques applicatives.</p><h3 id=2020--vers-une-architecture-temps-réel>2020 : Vers une architecture &ldquo;temps réel&rdquo;</h3><p>Début 2020, bonnes résolutions obligent, nous avons dressé un bilan de notre architecture, identifié les faiblesses et imaginé des solutions pour y remédier. Un travail qui nous a permis de dresser une feuille de route pour 2020 qui s’articule autour de deux grands axes.</p><p>Tout d’abord, l’aspect temps réel. Comme évoqué dans les paragraphes précédents, nous nous basons sur des <em>indexers</em> pour dénormaliser les données provenant du CMS dans des instances Elasticsearch. C’est une manière de faire relativement simple qui, bien que fonctionnelle, introduit une latence entre les mises à jour faites par les équipes éditoriales et leurs mises en ligne effectives sur les fronts. En effet nos <em>indexers</em> tournent régulièrement ce qui impose, suite à une modification, d’attendre l’indexation suivante pour que celle-ci soit mise en ligne.</p><p>Vient ensuite l’aspect performance. Depuis la refonte des produits MYTF1 (autant IPTV que OTT) les audiences sont en hausse. De plus nous continuons à déployer notre nouvelle application IPTV chez d’autres opérateurs (Orange entre autre) ce qui amène une charge supplémentaire sur nos services backend. Depuis 2 ans nous avons misé sur différentes mécaniques de mises en cache (CDN, cache HTTP, cache in-memory, etc.) pour être en mesure d’absorber la charge générée par l’activité des utilisateurs. Ces différentes couches de cache sont de moins en moins évidentes à maintenir et participent également à la latence des mises en ligne des contenus évoquée précédemment.</p><p>La solution que nous avons imaginée est de basculer vers une architecture événementielle :</p><p><img src=images/archi_2020.svg#darkmode alt="2020 -  Schéma d&amp;rsquo;architecture backend" title="2020 - Schéma d'architecture backend"></p><p>Pour ce faire, nous avons décidé de nous appuyer sur Kafka (plus précisément, l&rsquo;offre managée <a href=https://aws.amazon.com/msk/>MSK</a> d&rsquo;AWS). Plusieurs sources d&rsquo;événements ont été identifiées :</p><ul><li>Le CMS pour la partie contenu/édito, nous nous appuyons sur les <a href=https://docs.mongodb.com/manual/changeStreams/>Change Streams</a> MongoDB pour cela</li><li>Les fichiers parquet de recommandation que nous injectons dans des topics Kafka</li><li>Les actions des utilisateurs (lecture vidéo, enregistrement de l&rsquo;avancée de lecture, mise en favoris, etc..)</li></ul><p>Pour la partie CMS, l&rsquo;idée est de pousser toutes les modifications faites en base dans des topics Kafka dédiés (voir notre projet open source <a href=https://github.com/etf1/kafka-mongo-watcher>kafka-mongo-watcher</a>). Ensuite ces événements sont traités, transformés puis stockés (voir notre projet open source <a href=https://github.com/etf1/kafka-transformer>kafka-transformer</a>) dans des instances <a href=https://aws.amazon.com/fr/elasticache/redis/>Elasticache Redis</a>. Nous maintenons alors à jour, en quasi temps réel, notre catalogue de contenu dans un cache partagé sur lequel nous avons directement branché nos instances GraphQL. Deux conséquences : nous ne sommes plus dépendants des <em>indexers</em> de données et nous avons supprimé la couche de cache in-memory (non partagée) de notre API GraphQL. De plus nous avons dénormalisé les données dans Redis de telle manière que le service catalogue devient superflu. Ainsi nous gagnons sur les deux tableaux (latence liée à l&rsquo;indexation et performance de l&rsquo;API GraphQL).</p><p>Pour traiter certains cas particuliers, nous avons recours à <a href=https://github.com/lovoo/goka>Goka</a> pour, par exemple, permettre la jointure et l&rsquo;aggrégation de données en provenance de plusieurs types d&rsquo;événements différents (exemple : jointure entre les mises à jour des programmes et des vidéos pour produire des curations éditoriales qui sont ensuite stockées dans Redis). Enfin, nous avons introduit un composant <em>scheduler</em> dont l&rsquo;objectif est de produire des événements temporels sur lesquels le système va pouvoir réagir (exemple : expiration d&rsquo;une vidéo).</p><p>Pour la partie utilisateur, nous avons conservé globalement la même architecture qu&rsquo;avant mais en la modernisant :</p><ul><li>Fusion au sein d&rsquo;une seule API des données utilisateurs</li><li>Bascule vers DynamoDB (à la place des instances Elasticsearch)</li><li>Bascule sur Kafka (à la place de RabbitMQ)</li><li>Migration de l&rsquo;instance Redis vers Elasticache</li></ul><p>Enfin pour la partie recommandation nous avons :</p><ul><li>Injecté les fichiers parquet directement dans Kafka</li><li>Remplacé la base Elasticsearch par une base DynamoDB pour le stockage à froid</li><li>Ajouté une instance Redis qui agit comme cache partagé</li><li>Introduit, gràce à notre équipe data, une nouvelle API de recommandation temps réel</li></ul><p>Dans les deux cas, nous profitons maintenant des possibilités de mise à l&rsquo;échelle automatique de DynamoDB et des performances accrues des services managés MSK et Elasticache.</p><p>Toutes ces modifications permettent donc des gains notables sur la performance, la mise à l&rsquo;échelle et la réduction des latences de notre architecture. Mais nous sommes encore en phase transitoire et d&rsquo;autres évolutions sont déjà prévues, notamment autour de la médiathèque et du pré-chargement des données dans notre CDN, mais aussi sur le calcul des tops vidéos et programmes en temps réel.</p><h2 id=conclusion>Conclusion</h2><p>Comme vous avez pu le constater à la lecture de cet article, les dernières années ont été riches pour l&rsquo;équipe Backend. Je tiens personnellement à remercier toute l&rsquo;équipe pour son travail, ses compétences et sa capacité à remettre en question ses choix pour oeuvrer à l&rsquo;amélioration continue de notre architecture (le tout dans une super ambiance 😀). Bien que dense, cet article ne fait qu&rsquo;effleurer certains aspects techniques. Nous les développerons dans de futurs articles qui, nous l&rsquo;espérons, réussiront à capter votre attention.</p><h2 id=remerciements>Remerciements</h2><p>Merci aux relecteurs de l&rsquo;article : Sabine, Déborah, Guillaume, Richard, Thierry et Vincent.</p></article><section id=articleNext class="section nartrow"><h3 class=footer-next-heading>Plus d'articles</h3><div class=footer-spacer></div><div class=next-articles-grid numberofarticles={numberOfArticles}><div class=post-row><a href=/post/2020/architecture/graphql-and-persisted-queries/ class=article-link id=article-link-bigger><div><div class=image-container><img src=/post/2020/architecture/graphql-and-persisted-queries/images/hero-v2.jpg class=article-image></div><div><h2 class=article-title>GraphQL et les persisted queries</h2><p class=article-excerpt>La gestion du cache et l'utilisation des persisted queries avec GraphQL</p><div class=article-metadata>25 novembre 2020 • 5 minutes</div></div></div></a><a href=/post/2020/architecture/video/ class=article-link><div><div class=image-container><img src=/post/2020/architecture/video/images/hero.jpg class=article-image></div><div><h2 class=article-title>La vidéo</h2><p class=article-excerpt>Le fonctionnement de la plateforme vidéo de MYTF1</p><div class=article-metadata>22 octobre 2020 • 12 minutes</div></div></div></a></div></div></section></section><script src=/js/progressBar.js></script><div class=footer-gradient></div><div class="section narrow"><div class=footer-hr></div><div class=footer-container><div class=footer-text><img src=/images/logo_tf1lg.png class=footer-logo>TF1 Copyright © 2025 e-TF1</div><div class=social-icon-outer><div class=social-icon-container><a href=https://www.welcometothejungle.com/fr/companies/groupe-tf1><svg class="social-icon-image" viewBox="7 7 26 26" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" alt="Rejoingez nous !" title="Rejoignez nous !"><path d="M31.347322 11.295661C30.1466441 9.31125424 26.6585085 8.44345763 24.1202034 11.0048136 23.9785085 11.1532881 23.7913898 11.6054915 24.3554576 12.2149831c1.181017 1.258305 7.340339 7.7179661 5.0616949 13.36-1.1071186 2.7430508-4.2555932 2.2705084-5.438644-2.2738984C23.4991864 21.4590508 22.7595254 17.6326102 23.468678 13.0393898 23.468678 13.0393898 23.5818983 12.6082034 23.3995254 12.4705763 23.2734237 12.3743051 23.0707119 12.4143051 22.8103729 12.8312542 22.7452881 12.936339 22.7588475 12.9146441 22.6964746 13.0265085L22.6924068 13.0285424c-1.7457627 2.9444068-3.5220339 6.4352542-4.3579661 7.7444068C18.7425763 18.7980339 18.2252881 16.0814237 17.4185085 13.8075254L17.2666441 13.396678C16.5215593 11.4515932 15.6259661 10.1390508 15.3541017 9.84142373 15.3215593 9.80549153 15.2408814 9.73837288 14.9744407 9.73837288H7.42461017c-.528135590000001.0-.4820339.45220342-.31525424.615593219999999 2.00474576 2.3857627 7.84610167 11.3294915 5.13762717 20.1064407C12.0381695 31.1390508 12.3663051 31.4949831 12.9066441 30.7946441c2.3742373-3.0772882 5.32-8.3227119 7.4542373-12.2542373C19.8903729 19.9037966 19.4761356 21.4217627 19.2544407 23.0122712c-.4677966 3.3572881.5247457 5.8827119 1.2508474 7.2081356C20.8768136 30.8990508 21.3696949 31.3139661 22.6456271 31.1241356c6.5071187-.9694915 8.6772882-6.7016949 9.4786441-9.6088136C33.5852881 16.215661 32.5154576 13.2258305 31.347322 11.295661" id="monogram" fill="#000"/></svg></a><span class=hidden>https://www.welcometothejungle.com/fr/companies/groupe-tf1</span>
<a href=https://www.linkedin.com/company/e-tf1/><svg class="social-icon-image" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M3.59615 13.125H.871552V4.36523H3.59615V13.125zM2.24847 3.16406c-.42969.0-.80078-.15625-1.11328-.46875-.312498-.3125-.468747-.6836-.468747-1.11328.0-.42969.156249-.800782.468747-1.113281C1.44769.156249 1.81878.0 2.24847.0s.80078.156249 1.11328.468749c.3125.312499.46875.683591.46875 1.113281.0.42968-.15625.80078-.46875 1.11328s-.68359.46875-1.11328.46875zM13.7915 13.125H11.0669V8.84765C11.0669 8.14452 11.0083 7.63671 10.8911 7.32421c-.2148-.52734-.6348-.79101-1.25976-.79101-.625.0-1.06445.23437-1.31836.70312C8.11767 7.58788 8.02001 8.10546 8.02001 8.78905V13.125H5.32471V4.36523H7.93212V5.5664H7.96142C8.15673 5.17578 8.46923 4.85351 8.89892 4.59961c.46875-.3125 1.01562-.46875 1.64058-.46875 1.2696.0 2.1582.40039 2.666 1.20117C13.5962 5.97656 13.7915 6.97265 13.7915 8.3203V13.125z" fill="#73737d"/></svg></a><span class=hidden>https://www.linkedin.com/company/e-tf1/</span>
<a href=https://github.com/etf1><svg class="social-icon-image" width="14" height="14" viewBox="0 0 14 14" fill="none" xmlns="http://www.w3.org/2000/svg"><path fillRule="evenodd" clipRule="evenodd" d="M7 0C3.1325.0.0 3.21173.0 7.17706.0 10.3529 2.00375 13.0353 4.78625 13.9863 5.13625 14.0491 5.2675 13.8338 5.2675 13.6454 5.2675 13.4749 5.25875 12.9097 5.25875 12.3087 3.5 12.6406 3.045 11.8691 2.905 11.4653 2.82625 11.259 2.485 10.622 2.1875 10.4516 1.9425 10.317 1.5925 9.98508 2.17875 9.97611 2.73 9.96714 3.12375 10.4964 3.255 10.7118c.63 1.0855 1.63625.7805 2.03875.5921C5.355 10.8374 5.53875 10.5234 5.74 10.3439 4.1825 10.1645 2.555 9.54549 2.555 6.80026c0-.7805.27125-1.42644.7175-1.92883C3.2025 4.692 2.9575 3.95635 3.3425 2.96951c0 0 .58625-.1884 1.925.73565.56-.16149 1.155-.24223 1.75-.24223s1.19.08074 1.75.24223c1.3388-.93302 1.925-.73565 1.925-.73565C11.0775 3.95635 10.8325 4.692 10.7625 4.87143 11.2087 5.37382 11.48 6.01079 11.48 6.80026c0 2.7542-1.63625 3.36424-3.19375 3.54364C8.54 10.5682 8.75875 10.9988 8.75875 11.6717 8.75875 12.6316 8.75 13.4032 8.75 13.6454 8.75 13.8338 8.88125 14.0581 9.23125 13.9863 11.9963 13.0353 14 10.3439 14 7.17706 14 3.21173 10.8675.0 7 0z" fill="#73737d"/></svg></a><span class=hidden>https://github.com/etf1</span>
<a href=https://tech.tf1.fr/index.xml><svg class="social-icon-image" style="width:1em;height:1em;vertical-align:middle;fill:currentColor;overflow:hidden" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path d="M329.142857 768q0 45.714286-32 77.714286t-77.714286 32-77.714285-32-32-77.714286 32-77.714286 77.714285-32 77.714286 32 32 77.714286zm292.571429 70.285714q1.142857 16-9.714286 27.428572-10.285714 12-26.857143 12H508q-14.285714.0-24.571429-9.428572T472 844.571429q-12.571429-130.857143-105.428571-223.714286T142.857143 515.428571Q128.571429 514.285714 119.142857 504T109.714286 479.428571V402.285714q0-16.571429 12-26.857143 9.714286-9.714286 24.571428-9.714285h2.857143q91.428571 7.428571 174.857143 46T472 515.428571q65.142857 64.571429 103.714286 148t46 174.857143zm292.571428 1.142857Q915.428571 854.857142 904 866.285714q-10.285714 11.428571-26.285714 11.428572H796q-14.857143.0-25.428571-10t-11.142858-24.285715Q752.571428 720.571428 701.714286 610T569.428571 418t-192-132.285714T144 227.428571q-14.285714-.571429-24.285714-11.142857t-10-24.857143V109.714286q0-16 11.428571-26.285715 10.285714-10.285714 25.142857-10.285714H148q149.714286 7.428571 286.571429 68.571429t243.142857 168q106.857143 106.285714 168 243.142857t68.571428 286.571428z"/></svg></a><span class=hidden>https://tech.tf1.fr/index.xml</span></div></div></div></div></div><script src=/js/prism.js></script></body></html>